{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "195f0488",
   "metadata": {},
   "source": [
    "# Jupiter FAQ Bot - Performance Evaluation\n",
    "\n",
    "This notebook provides comprehensive evaluation and analysis of the Jupiter FAQ Bot system.\n",
    "\n",
    "The Jupiter FAQ Bot is designed to answer questions about Jupiter banking services using:\n",
    "- Web-scraped FAQ data (sample data in this demo)\n",
    "- Semantic search with sentence transformers\n",
    "- FAISS vector similarity search\n",
    "- Optional LLM integration for natural responses\n",
    "\n",
    "1. **Confidence Score Distribution**: How confident the bot is in its answers\n",
    "2. **Semantic Similarity**: Consistency across paraphrased questions\n",
    "3. **Category Performance**: Accuracy by FAQ category\n",
    "4. **Response Quality**: Length, clarity, and appropriateness\n",
    "5. **Edge Case Handling**: Behavior with irrelevant or malformed queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e89685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.bot import JupiterFAQBot\n",
    "from src.utils import load_json_file\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08617f06",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Bot Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f16ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the bot\n",
    "bot = JupiterFAQBot()\n",
    "initialization_success = bot.initialize()\n",
    "\n",
    "print(f\"Bot initialization: {'âœ… Success' if initialization_success else 'âŒ Failed'}\")\n",
    "\n",
    "if initialization_success:\n",
    "    raw_faqs = load_json_file('../data/raw_faqs.json')\n",
    "    processed_faqs = load_json_file('../data/processed_faqs.json')\n",
    "    \n",
    "    print(f\"Raw FAQs loaded: {len(raw_faqs)}\")\n",
    "    print(f\"Processed FAQs loaded: {len(processed_faqs)}\")\n",
    "    \n",
    "    categories = bot.get_all_categories()\n",
    "    print(f\"Available categories: {categories}\")\n",
    "else:\n",
    "    print(\"Cannot proceed with evaluation - bot initialization failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946e2fd",
   "metadata": {},
   "source": [
    "## 2. FAQ Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894b0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "if initialization_success:\n",
    "    category_counts = Counter([faq.get('category', 'Unknown') for faq in processed_faqs])\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    categories_list = list(category_counts.keys())\n",
    "    counts_list = list(category_counts.values())\n",
    "    \n",
    "    bars = plt.bar(categories_list, counts_list, color=sns.color_palette(\"husl\", len(categories_list)))\n",
    "    plt.title('FAQ Distribution by Category', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Category', fontsize=12)\n",
    "    plt.ylabel('Number of FAQs', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“Š Category Statistics:\")\n",
    "    for category, count in category_counts.most_common():\n",
    "        percentage = (count / len(processed_faqs)) * 100\n",
    "        print(f\"  {category}: {count} FAQs ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedebb1",
   "metadata": {},
   "source": [
    "## 3. Test Query Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f756435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if initialization_success:\n",
    "    test_queries = {\n",
    "        'Payments': [\n",
    "            'How do I make a payment using Jupiter?',\n",
    "            'What are different ways to send money?',\n",
    "            'How can I pay my bills?',\n",
    "            'Can I schedule payments for later?',\n",
    "            'How to transfer money to someone?'\n",
    "        ],\n",
    "        'KYC': [\n",
    "            'What documents are required for KYC verification?',\n",
    "            'How long does KYC take?',\n",
    "            'What if my KYC is rejected?',\n",
    "            'Can I use Jupiter without KYC?',\n",
    "            'KYC verification process'\n",
    "        ],\n",
    "        'Rewards': [\n",
    "            'How do Jupiter rewards work?',\n",
    "            'How to earn reward points?',\n",
    "            'How can I redeem my points?',\n",
    "            'Do reward points expire?',\n",
    "            'What are Jupiter benefits?'\n",
    "        ],\n",
    "        'Cards': [\n",
    "            'How do I activate my debit card?',\n",
    "            'What are the card charges?',\n",
    "            'Can I use card internationally?',\n",
    "            'What if my card is lost?',\n",
    "            'Jupiter debit card features'\n",
    "        ],\n",
    "        'Limits': [\n",
    "            'What are the transaction limits?',\n",
    "            'How to increase limits?',\n",
    "            'ATM withdrawal limit?',\n",
    "            'Bill payment limits?',\n",
    "            'Daily transfer limits'\n",
    "        ],\n",
    "        'Edge Cases': [\n",
    "            'What is the weather today?',  # Irrelevant\n",
    "            'asdfghjkl',  # Random text\n",
    "            'How to cook pasta?',  # Unrelated\n",
    "            'Jupiter Mars mission'  # Confusing context\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    print(\"ğŸ§ª Testing bot performance...\\n\")\n",
    "    \n",
    "    for category, queries in test_queries.items():\n",
    "        print(f\"Testing {category} queries...\")\n",
    "        \n",
    "        for query in queries:\n",
    "            if query:  # Skip empty queries for now\n",
    "                response = bot.get_response(query)\n",
    "                \n",
    "                results.append({\n",
    "                    'category': category,\n",
    "                    'query': query,\n",
    "                    'confidence': response['confidence'],\n",
    "                    'response_length': len(response['response']),\n",
    "                    'has_sources': len(response['source_faqs']) > 0,\n",
    "                    'has_suggestions': len(response['suggestions']) > 0,\n",
    "                    'response': response['response'][:100] + '...' if len(response['response']) > 100 else response['response']\n",
    "                })\n",
    "    \n",
    "    df_results = pd.DataFrame(results)\n",
    "    print(f\"\\nâœ… Completed testing {len(results)} queries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8122f16",
   "metadata": {},
   "source": [
    "## 4. Confidence Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d776c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if initialization_success and len(results) > 0:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.hist(df_results['confidence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('Overall Confidence Distribution', fontweight='bold')\n",
    "    plt.xlabel('Confidence Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.axvline(df_results['confidence'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {df_results[\"confidence\"].mean():.2f}')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    category_confidence = df_results.groupby('category')['confidence'].mean().sort_values(ascending=False)\n",
    "    bars = plt.bar(range(len(category_confidence)), category_confidence.values, \n",
    "                   color=sns.color_palette(\"husl\", len(category_confidence)))\n",
    "    plt.title('Average Confidence by Category', fontweight='bold')\n",
    "    plt.xlabel('Category')\n",
    "    plt.ylabel('Average Confidence')\n",
    "    plt.xticks(range(len(category_confidence)), category_confidence.index, rotation=45)\n",
    "    \n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                f'{height:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    confidence_ranges = {\n",
    "        'High (â‰¥0.8)': len(df_results[df_results['confidence'] >= 0.8]),\n",
    "        'Medium (0.6-0.8)': len(df_results[(df_results['confidence'] >= 0.6) & (df_results['confidence'] < 0.8)]),\n",
    "        'Low (<0.6)': len(df_results[df_results['confidence'] < 0.6])\n",
    "    }\n",
    "    \n",
    "    colors = ['green', 'orange', 'red']\n",
    "    plt.pie(confidence_ranges.values(), labels=confidence_ranges.keys(), autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90)\n",
    "    plt.title('Confidence Score Ranges', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ Confidence Score Statistics:\")\n",
    "    print(f\"  Mean confidence: {df_results['confidence'].mean():.3f}\")\n",
    "    print(f\"  Median confidence: {df_results['confidence'].median():.3f}\")\n",
    "    print(f\"  Standard deviation: {df_results['confidence'].std():.3f}\")\n",
    "    print(f\"  High confidence queries (â‰¥0.8): {len(df_results[df_results['confidence'] >= 0.8])}/{len(df_results)} ({len(df_results[df_results['confidence'] >= 0.8])/len(df_results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a2afa7",
   "metadata": {},
   "source": [
    "## 5. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c4d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ¯ Jupiter FAQ Bot Evaluation Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if initialization_success and len(results) > 0:\n",
    "    high_confidence_ratio = len(df_results[df_results['confidence'] >= 0.7]) / len(df_results)\n",
    "    coverage_ratio = df_results['has_sources'].sum() / len(df_results)\n",
    "    \n",
    "    print(f\"ğŸ“Š Total queries tested: {len(results)}\")\n",
    "    print(f\"ğŸ“ˆ High confidence responses (â‰¥0.7): {high_confidence_ratio*100:.1f}%\")\n",
    "    print(f\"ğŸ“š Queries with source FAQs: {coverage_ratio*100:.1f}%\")\n",
    "    print(f\"ğŸ¯ Average confidence score: {df_results['confidence'].mean():.3f}\")\n",
    "    \n",
    "    if high_confidence_ratio >= 0.8:\n",
    "        performance = \"Excellent âœ…\"\n",
    "    elif high_confidence_ratio >= 0.6:\n",
    "        performance = \"Good ğŸ‘\"\n",
    "    else:\n",
    "        performance = \"Needs Improvement âš ï¸\"\n",
    "    \n",
    "    print(f\"\\nğŸ† Overall Performance: {performance}\")\n",
    "    \n",
    "    print(\"\\nğŸš€ Key Strengths:\")\n",
    "    print(\"  âœ… Comprehensive FAQ coverage across multiple categories\")\n",
    "    print(\"  âœ… Semantic search with high-quality embeddings\")\n",
    "    print(\"  âœ… Confidence-based response system\")\n",
    "    print(\"  âœ… User-friendly Streamlit interface\")\n",
    "    print(\"  âœ… Modular, extensible architecture\")\n",
    "    \n",
    "    print(\"\\nğŸ’¡ Recommendations for Improvement:\")\n",
    "    print(\"  ğŸŒ Add multilingual support (Hindi/Hinglish)\")\n",
    "    print(\"  ğŸ¤– Integrate OpenAI API for more natural responses\")\n",
    "    print(\"  ğŸ“± Optimize for mobile and voice queries\")\n",
    "    print(\"  ğŸ”„ Implement real-time FAQ updates\")\n",
    "    print(\"  ğŸ“Š Add user feedback and analytics\")\n",
    "    print(\"  ğŸ¯ Personalize responses based on user context\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ Evaluation could not be completed due to initialization issues\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ“‹ Evaluation Complete!\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
